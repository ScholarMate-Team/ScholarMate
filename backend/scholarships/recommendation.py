import openai
import json
import re
from datetime import datetime
from django.db.models import QuerySet, Q, Case, When, Value
from django.conf import settings
from scholarships.models import Scholarship
from userinfor.models import UserScholarship
from django.db import models
from typing import List, Dict # íƒ€ì… íŒíŠ¸ ì¶”ê°€

# --- API í‚¤ ì„¤ì • ---
openai.api_key = settings.OPENAI_API_KEY

# (GPT ìƒí˜¸ì‘ìš© í—¬í¼ í•¨ìˆ˜ë“¤ì€ ë³€ê²½ ì—†ìŒ)
def call_gpt(prompt: str) -> str:
    """OpenAI GPT ëª¨ë¸ì„ í˜¸ì¶œí•˜ê³  ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # ğŸš¨ ì‹¤ì œ ì‚¬ìš© ì‹œ openai.api_key ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë‹¹ì‹ ì€ ì¥í•™ê¸ˆ ì¶”ì²œ ì‚¬ìœ ë¥¼ ì‘ì„±í•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                        "í•­ìƒ êµ¬ì²´ì ì´ê³  ë¬¸ë‹¨í˜•ìœ¼ë¡œ, ìµœì†Œ 3ë¬¸ì¥ ì´ìƒìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.4,       # ê¸°ì¡´ 0.1 â†’ 0.4 ë¡œ ì™„í™”
            request_timeout=60,    # ê¸°ì¡´ ê¸°ë³¸ê°’(15ì´ˆ) â†’ 60ì´ˆë¡œ í™•ì¥
        )
        gpt_response_content = response["choices"][0]["message"]["content"]
        print("DEBUG: [GPT ì‘ë‹µ ì›ë³¸]")
        print(gpt_response_content)
        return gpt_response_content

    except openai.error.OpenAIError as e:
        print(f"DEBUG: ì˜¤ë¥˜: OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return ""
    except Exception as e:
        print(f"DEBUG: ì˜¤ë¥˜: GPT í˜¸ì¶œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""


def extract_json_from_gpt_response(gpt_response_content: str) -> str:
    """GPT ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ë°°ì—´ ë˜ëŠ” ê°ì²´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    # ğŸš¨ GPTê°€ ë¶ˆí•„ìš”í•œ ì„œë¬¸ê³¼ í•¨ê»˜ JSONì„ ë°˜í™˜í•˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ JSONë§Œ ì¶”ì¶œ
    match = re.search(r"\[.*\]|{.*}", gpt_response_content, re.DOTALL)
    return match.group(0) if match else "[]"

def safe_parse_json(response_text: str):
    """GPT ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSONì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±í•©ë‹ˆë‹¤."""
    try:
        json_str = extract_json_from_gpt_response(response_text)
        return json.loads(json_str) if json_str.strip() else []
    except (json.JSONDecodeError, Exception) as e:
        # ğŸš¨ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë””ë²„ê¹…ì„ ìœ„í•´ ì‘ë‹µ ë‚´ìš© ì¼ë¶€ë¥¼ ì¶œë ¥
        print(f"ì˜¤ë¥˜: JSON íŒŒì‹± ì‹¤íŒ¨: {e} - ì‘ë‹µ ë‚´ìš©: '{response_text[:200]}...'")
        return []

# ------------------------------------------------------------------------------
# --- 2ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„ ë° ì‚¬ì „ í•„í„°ë§ í—¬í¼ í•¨ìˆ˜ ---
# ------------------------------------------------------------------------------

def _scholarship_to_simplified_dict(scholarship_obj):
    """GPTê°€ ìƒì„¸ ë¹„êµë¥¼ í•  ìˆ˜ ìˆë„ë¡, ì›ë³¸ ìƒì„¸ í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤."""     
    return {
        "product_id": scholarship_obj.product_id,
        "name": scholarship_obj.name, 
        "product_type": scholarship_obj.product_type,
        "university_type": scholarship_obj.university_type,
        "academic_year_type": scholarship_obj.academic_year_type,
        "major_field": scholarship_obj.major_field, 
        "region": scholarship_obj.region,
        # ğŸš¨ GPTê°€ ìƒì„¸ ë¶„ì„ì„ ìœ„í•´ í•„ìš”ë¡œ í•˜ëŠ” ìƒì„¸ ì¡°ê±´ í•„ë“œ
        "grade_criteria_details": scholarship_obj.grade_criteria_details,
        "income_criteria_details": scholarship_obj.income_criteria_details,
        "specific_qualification_details": scholarship_obj.specific_qualification_details,
    }

def filter_scholarships_by_date(scholarships_queryset: QuerySet) -> QuerySet:
    """ëª¨ì§‘ ê¸°ê°„ ë‚´ì˜ ì¥í•™ê¸ˆë§Œ í•„í„°ë§í•©ë‹ˆë‹¤."""
    # ğŸš¨ ëª¨ë¸ í•„ë“œ ì ‘ê·¼ ë°©ì‹ì€ ì‹¤ì œ Django ëª¨ë¸ ì •ì˜ì— ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
    current_date = datetime.now().date()
    filtered_qs = scholarships_queryset.filter(
            recruitment_start_date__lte=current_date,
            recruitment_end_date__gte=current_date
        )
    print(f"DEBUG: [0. ë‚ ì§œ í•„í„°ë§] í•„í„°ë§ í›„ ì¥í•™ê¸ˆ ìˆ˜: {filtered_qs.count()}")
    return filtered_qs

def filter_basic(scholarships_queryset: QuerySet, user_profile: UserScholarship) -> QuerySet:
    """ëŒ€í•™ ìœ í˜•, í•™ë…„, ì „ê³µì„ ê¸°ì¤€ìœ¼ë¡œ 1ì°¨ í•„í„°ë§í•©ë‹ˆë‹¤."""
    print(f"DEBUG: [1. ê¸°ë³¸ í•„í„°ë§] ì‚¬ìš©ì í”„ë¡œí•„: ëŒ€í•™='{user_profile.university_type}', í•™ë…„='{user_profile.academic_year_type}', ì „ê³µ='{user_profile.major_field}'")
    current_filtered_qs = scholarships_queryset
    
    # ëŒ€í•™ ìœ í˜• í•„í„°ë§ (ìœ ì‚¬ì„± ë§¤ì¹­)
    if user_profile.university_type and user_profile.university_type.strip():
        all_university_types = current_filtered_qs.values_list('university_type', flat=True).distinct()
        user_univ_type_normalized = user_profile.university_type.strip().replace('-', '~')
        matching_types = [db_type for db_type in all_university_types if user_univ_type_normalized in db_type.replace('-', '~')]
        if matching_types:
            current_filtered_qs = current_filtered_qs.filter(university_type__in=matching_types)
    
    # í•™ë…„ ìœ í˜• í•„í„°ë§ (ìœ ì‚¬ì„± ë§¤ì¹­)
    if user_profile.academic_year_type and user_profile.academic_year_type.strip():
        all_academic_years_in_db = current_filtered_qs.values_list('academic_year_type', flat=True).distinct()
        user_academic_year_normalized = user_profile.academic_year_type.strip().replace(' ', '')
        matching_academic_years = [db_year for db_year in all_academic_years_in_db if user_academic_year_normalized in db_year.replace(' ', '')]
        if matching_academic_years:
            current_filtered_qs = current_filtered_qs.filter(academic_year_type__in=matching_academic_years)
            
    # í•™ê³¼(ì „ê³µ) í•„í„°ë§ (ì‚¬ìš©ì ì „ê³µ ë˜ëŠ” ì „ê³µë¬´ê´€)
    user_major_field = getattr(user_profile, 'major_field', None)
    if user_major_field and user_major_field.strip():
        # 'ì „ê³µë¬´ê´€' ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¥í•™ê¸ˆê³¼ ì‚¬ìš©ì ì „ê³µì´ í¬í•¨ëœ ì¥í•™ê¸ˆ í•„í„°ë§
        all_major_keywords = ["í•´ë‹¹ì—†ìŒ", "ì œí•œì—†ìŒ", "ì „ê³µë¬´ê´€", "íŠ¹ì •í•™ê³¼"] 
        q_objects = Q(major_field__icontains=user_major_field.strip()) | Q(major_field__in=all_major_keywords)
        current_filtered_qs = current_filtered_qs.filter(q_objects)

    print(f"DEBUG: [1. ê¸°ë³¸ í•„í„°ë§] ìµœì¢… ê¸°ë³¸ í•„í„°ë§ ì ìš© í›„ ì¥í•™ê¸ˆ ìˆ˜: {current_filtered_qs.count()}")
    return current_filtered_qs

def filter_by_region_preprocessed(scholarships_queryset: QuerySet, user_profile: UserScholarship) -> QuerySet:
    """ì‚¬ìš©ì ê±°ì£¼ ì§€ì—­ ë˜ëŠ” ì „êµ­ ë‹¨ìœ„ ì¥í•™ê¸ˆë§Œ í•„í„°ë§í•©ë‹ˆë‹¤."""
    user_region_do = getattr(user_profile, 'region', '') or ""
    user_district = getattr(user_profile, 'district', '') or ""
    
    user_region_parts = list(filter(None, [user_region_do.strip(), user_district.strip()]))
    full_user_region = ' '.join(user_region_parts)
    print(f"DEBUG: [2. ì§€ì—­ í•„í„°ë§] ì¡°í•©ëœ ì‚¬ìš©ì ì§€ì—­: '{full_user_region}'")

    if not full_user_region:
        # ì§€ì—­ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì „êµ­ë§Œ í•„í„°ë§
        return scholarships_queryset.filter(region__icontains="ì „êµ­")

    # ì‹œ/ë„, ì‹œ/êµ°/êµ¬, ê·¸ë¦¬ê³  ì „êµ­ì„ í¬í•¨í•˜ëŠ” ì¡°ê±´
    exact_match_conditions = [full_user_region] + user_region_parts
    q_objects = Q(region__in=exact_match_conditions) | Q(region__icontains="ì „êµ­")
    
    filtered_qs = scholarships_queryset.filter(q_objects).distinct()
    print(f"DEBUG: [2. ì§€ì—­ í•„í„°ë§] í•„í„°ë§ í›„ ì¥í•™ê¸ˆ ìˆ˜: {filtered_qs.count()}")
    return filtered_qs


# ------------------------------------------------------------------------------
# --- 3ë‹¨ê³„: GPT ìµœì¢… ë­í‚¹ í•¨ìˆ˜ --- 
# ------------------------------------------------------------------------------

def recommend_final_scholarships_by_gpt(filtered_scholarships_queryset: QuerySet, user_profile: UserScholarship) -> List[Dict]:
    """
    GPTì—ê²Œ ìµœì¢… ì¶”ì²œ ì´ìœ ê¹Œì§€ ì‘ì„±í•˜ë„ë¡ ìœ„ì„í•˜ê³ , ê²°ê³¼ë¥¼ Scholarship ê°ì²´ì™€ Reasonì„ í¬í•¨í•œ
    ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì—¬ í›„ì† ì²˜ë¦¬ê°€ ìš©ì´í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    """
    print(f"DEBUG: [3. GPT ìµœì¢… ì¶”ì²œ] GPT í˜¸ì¶œ ì „ í›„ë³´êµ° ìˆ˜: {filtered_scholarships_queryset.count()}")
    if filtered_scholarships_queryset.count() == 0:
        return []

    # --- 1. ì ìˆ˜ì œ ìƒ˜í”Œë§ ---
    user_region_do = getattr(user_profile, 'region', '') or ""
    user_district = getattr(user_profile, 'district', '') or ""
    full_user_region = ' '.join(filter(None, [user_region_do.strip(), user_district.strip()]))
    user_major = getattr(user_profile, 'major_field', '') or ""

    # ì§€ì—­/ì „ê³µ ì¼ì¹˜ë„ì— ë”°ë¼ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ìƒìœ„ 20ê°œë¥¼ ìƒ˜í”Œë§
    score_annotation = Case(
        When(region=full_user_region, then=Value(10)),
        When(region=user_region_do, then=Value(7)),
        When(major_field__icontains=user_major, then=Value(5)),
        When(region__icontains="ì „êµ­", then=Value(1)),
        default=Value(0),
        output_field=models.IntegerField()
    )
    
    scored_queryset = filtered_scholarships_queryset.annotate(
        relevance_score=score_annotation
    ).order_by('-relevance_score')

    sample_size = 20
    actual_sample_size = min(scored_queryset.count(), sample_size)
    sampled_queryset_for_gpt = scored_queryset[:actual_sample_size]
    
    print(f"DEBUG: [3. GPT ìµœì¢… ì¶”ì²œ] ì ìˆ˜ì œ ìƒ˜í”Œë§ í›„ GPT ë¶„ì„ ëŒ€ìƒ ìˆ˜: {len(sampled_queryset_for_gpt)}")
    sampled_scholarships_for_gpt = [_scholarship_to_simplified_dict(s) for s in sampled_queryset_for_gpt]
    
    # --- 2. ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ ---
    user_info_dict = user_profile.to_dict() # UserScholarship ëª¨ë¸ì— to_dict()ê°€ ìˆë‹¤ê³  ê°€ì •
    user_info_dict['region'] = full_user_region
    user_info_dict.pop('district', None)
    
    # ğŸš¨ ì‹¤ì œ ìƒ˜í”Œë§ í¬ê¸°ë¥¼ ë°˜ì˜í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
    prompt = f"""
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í”„ë¡œí•„ê³¼ ì¥í•™ê¸ˆ ìê²© ì¡°ê±´ì„ ë¹„êµí•˜ì—¬, ê°œì¸í™”ëœ ì¶”ì²œ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ëŠ” AI ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
    
    [ì‚¬ìš©ì í”„ë¡œí•„]
    {json.dumps(user_info_dict, ensure_ascii=False, indent=2)}

    [ë¶„ì„ ëŒ€ìƒ ì¥í•™ê¸ˆ ëª©ë¡]
    {json.dumps(sampled_scholarships_for_gpt, ensure_ascii=False, indent=2)}
    
    [ì—…ë¬´ ì§€ì‹œ]

    ì‚¬ìš©ì í”„ë¡œí•„ê³¼ ì¥í•™ê¸ˆ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬, ëª©ë¡ ë‚´ì— ìˆëŠ” **ì´ {actual_sample_size}ê°œì˜ ì¥í•™ê¸ˆ**ì„ ì í•©ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

    **[ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™]**

    1.  **ì‚¬ì‹¤ ê¸°ë°˜ ì‘ì„±:** reason'ì„ ì‘ì„±í•  ë•ŒëŠ” ì•„ë˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¥´ê³ , **ê·œì¹™ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ** ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”. ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
        ê·œì¹™1.  **ì§€ì—­ ì¡°ê±´:** ì‚¬ìš©ìì˜ ì§€ì—­('{user_info_dict.get("region")}')ê³¼ ì¥í•™ê¸ˆì˜ 'region'ì´ êµ¬ì²´ì ìœ¼ë¡œ ì¼ì¹˜í• ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ì„¸ìš”. 'ì „êµ­'ì€ ê·¸ ë‹¤ìŒì…ë‹ˆë‹¤.
        ê·œì¹™2.  **ì„±ì  ì¡°ê±´:** ì‚¬ìš©ìì˜ ì„±ì (gpa_last_semester, gpa_overall)ê³¼ ì¥í•™ê¸ˆì˜ 'grade_criteria_details'ë¥¼ ë¹„êµí•˜ì—¬, ê¸°ì¤€ì„ ì¶©ì¡±í•˜ë©´ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.
        ê·œì¹™3.  **ì†Œë“ ì¡°ê±´:** ì‚¬ìš©ìì˜ ì†Œë“ë¶„ìœ„('income_level')ì™€ ì¥í•™ê¸ˆì˜ 'income_criteria_details'ë¥¼ ë¹„êµí•˜ì—¬, ê¸°ì¤€ì— ë¶€í•©í•˜ë©´ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.
        ê·œì¹™4.  **íŠ¹ì • ìê²© ì¡°ê±´ (ê°€ì‚°ì  í•­ëª©):**
            - ë§Œì•½ ì‚¬ìš©ìì˜ 'is_multi_cultural_family'ê°€ Trueì´ê³ , ì¥í•™ê¸ˆ ì„¤ëª…(ì£¼ë¡œ 'specific_qualification_details')ì— 'ë‹¤ë¬¸í™”'ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë†’ì€ ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.
            - ë§Œì•½ ì‚¬ìš©ìì˜ 'is_single_parent_family'ê°€ Trueì´ê³ , ì¥í•™ê¸ˆì˜ 'income_criteria_details'ì— 'í•œë¶€ëª¨', 'ê°€ì •í˜•í¸', 'ê²½ì œì‚¬ì •'ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë†’ì€ ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.
            - ë§Œì•½ ì‚¬ìš©ìì˜ 'is_multiple_children_family'ê°€ Trueì´ê³ , ì¥í•™ê¸ˆì˜'income_criteria_details'ì— 'ë‹¤ìë…€'ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë†’ì€ ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.
            - ë§Œì•½ ì‚¬ìš©ìì˜ 'is_national_merit'ê°€ Trueì´ê³ , ì¥í•™ê¸ˆì˜'income_criteria_details'ì— 'êµ­ê°€ìœ ê³µì' ë˜ëŠ” 'ë³´í›ˆ'ì´ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë†’ì€ ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.
        ê·œì¹™5.  **ê¸°íƒ€ ì¡°ê±´:** ìœ„ ì¡°ê±´ ì™¸ì—ë„ ì‚¬ìš©ìì˜ ì „ê³µ, í•™ë…„ ë“±ì´ ì¥í•™ê¸ˆì˜ ì¡°ê±´ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.

    2.  **êµ¬ì²´ì ì¸ ì´ìœ  ì œì‹œ:** 'reason'ì—ëŠ” ì™œ ì´ ì¥í•™ê¸ˆì´ ì‚¬ìš©ìì—ê²Œ ì í•©í•œì§€, ì–´ë–¤ ì¡°ê±´(ì§€ì—­, ì„±ì , ì†Œë“, ì „ê³µ, í•™ë…„, íŠ¹ì • ìê²© ë“±)ì´ ì–´ë–»ê²Œ ë¶€í•©í•˜ëŠ”ì§€ë¥¼ **3ë¬¸ì¥ ì´ìƒ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ í˜•íƒœë¡œ** ì‘ì„±í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, â€œê·€í•˜ëŠ” ê²½ê¸° ì§€ì—­ì˜ 4í•™ë…„ìƒìœ¼ë¡œ, í•´ë‹¹ ì¥í•™ê¸ˆì˜ ì§€ì—­ ìš”ê±´ê³¼ í•™ë…„ ì¡°ê±´ì„ ëª¨ë‘ ì¶©ì¡±í•©ë‹ˆë‹¤. ë˜í•œ ì„±ì  ê¸°ì¤€(3.5 ì´ìƒ)ì„ ë§Œì¡±í•˜ë©°, ì „êµ­ ë‹¨ìœ„ë¡œ ì§€ì› ê°€ëŠ¥í•´ ì ‘ê·¼ì„±ì´ ë†’ìŠµë‹ˆë‹¤.â€ ì™€ ê°™ì€ í˜•íƒœë¡œ ì‘ì„±í•˜ì„¸ìš”

    **[ì¶œë ¥ í˜•ì‹]**
    - ê° í•­ëª©ì€ 'product_id'ì™€ 'reason' ë‘ ê°œì˜ í‚¤ë¥¼ ê°€ì§„ JSON ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.
    - 'reason'ì€ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìµœì¢… ì¶”ì²œ ì‚¬ìœ (í•œêµ­ì–´ ë¬¸ìì—´)ì…ë‹ˆë‹¤. ë§Œì•½ ê·œì¹™4ë¡œ ì¸í•´ ê°€ì‚°ì ì„ ì–»ì€ ê²½ìš°, 'reason'ì— ê·¸ì™€ ê´€ë ¨ëœ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì„œìˆ í•˜ì„¸ìš”.
    - 'product_id'ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”.

    **[ì¶œë ¥ ì˜ˆì‹œ]**
    [
      {{
        "product_id": "ì¥í•™ê¸ˆB_ì§€ìì²´B",
        "reason": "ê±°ì£¼í•˜ì‹œëŠ” 'ê²½ê¸°ë„ íŒŒì£¼ì‹œ' ì§€ì—­ ì¡°ê±´ì— ë¶€í•©í•˜ë©°, ì§ì „ í•™ê¸° ì„±ì (4.1)ì´ ìš”êµ¬ ê¸°ì¤€(3.5 ì´ìƒ)ì„ ì¶©ì¡±í•©ë‹ˆë‹¤. ì´ ì¥í•™ê¸ˆì€ íŠ¹íˆ ë‹¤ìë…€ ê°€ì •ì— ëŒ€í•œ ìš°ëŒ€ ì¡°í•­ì´ ìˆì–´ ê°€ì‚°ì ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      }},

      {{
        "product_id": "ì¥í•™ê¸ˆA_ì¬ë‹¨A",
        "reason": "ê·€í•˜ì˜ ì†Œë“ ë¶„ìœ„ê°€ ì¥í•™ê¸ˆì˜ ê¸°ì¤€(8ë¶„ìœ„ ì´ë‚´)ì— ì •í™•íˆ ë¶€í•©í•˜ë©°, ì „êµ­ ë‹¨ìœ„ë¡œ ì§€ì› ê°€ëŠ¥í•´ ì ‘ê·¼ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë˜í•œ ì „ê³µ ë¶„ì•¼ì— ê´€ê³„ì—†ì´ ì§€ì›í•  ìˆ˜ ìˆì–´ ì í•©í•©ë‹ˆë‹¤."
      }}
    ]
    """

   # --- 3. GPT í˜¸ì¶œ ë° ê²°ê³¼ ì²˜ë¦¬ ---
    gpt_response_content = call_gpt(prompt)
    parsed_response = safe_parse_json(gpt_response_content)

    # ğŸš¨ GPT ì‘ë‹µì´ ìœ íš¨í•˜ì§€ ì•Šì„ ê²½ìš°, ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ í´ë°±
    if not isinstance(parsed_response, list) or not parsed_response:
        fallback_qs = scored_queryset[:min(scored_queryset.count(), 20)]
        return [
            {"product_id": s.product_id, "reason": "GPT ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì¶”ì²œ", "scholarship": s}
            for s in fallback_qs
        ]


    # GPTê°€ ë°˜í™˜í•œ IDê°€ ìƒ˜í”Œë§ í›„ë³´êµ°ì— ìˆëŠ”ì§€ ê²€ì¦
    valid_recommendations = []
    sampled_ids_map = {s.product_id: s for s in sampled_queryset_for_gpt}
    
    print("\n" + "="*25 + " GPT ì‘ë‹µ ìµœì†Œ ê²€ì¦ ì‹œì‘ " + "="*25)
    for item in parsed_response:
        product_id = item.get('product_id')
        # ğŸš¨ ID ìœ íš¨ì„± ë° í˜•ì‹ ê²€ì‚¬
        if isinstance(item, dict) and product_id and product_id in sampled_ids_map:
            # ìœ íš¨í•œ í•­ëª©ì— Scholarship ê°ì²´ë¥¼ ì¶”ê°€
            item['scholarship'] = sampled_ids_map[product_id]
            valid_recommendations.append(item)
            print(f" Â - âœ… ê²€ì¦ ì„±ê³µ (ID ìœ íš¨): {product_id}, ì´ìœ : {item.get('reason')}")
        else:
            print(f" Â - âŒ ê²€ì¦ ì‹¤íŒ¨ (ID ì˜¤ë¥˜ ë˜ëŠ” í™˜ê°): {product_id}")
    print("="*25 + " GPT ì‘ë‹µ ìµœì†Œ ê²€ì¦ ì™„ë£Œ " + "="*25 + "\n")

    if not valid_recommendations:
        print("ê²½ê³ : ê²€ì¦ì„ í†µê³¼í•œ ì¶”ì²œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì ìˆ˜ ê¸°ë°˜ í´ë°± ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        # í´ë°± ë¡œì§ì—ì„œë„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        fallback_qs = scored_queryset[:min(scored_queryset.count(), 20)]
        return [
            {"product_id": s.product_id, "reason": "ì¡°ê±´ ì¼ì¹˜ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ì¶”ì²œëœ ì¥í•™ê¸ˆì…ë‹ˆë‹¤.", "scholarship": s}
            for s in fallback_qs
        ]

    # --- 4. ìµœì¢… ê²°ê³¼ ìƒì„± ---
    # valid_recommendationsëŠ” ì´ë¯¸ GPTì˜ ì í•©ë„ ìˆœì„œëŒ€ë¡œ ì •ë ¬ë˜ì–´ ìˆë‹¤ê³  ê°„ì£¼í•©ë‹ˆë‹¤.
    final_results = valid_recommendations[:20] 
    
    print(f"DEBUG: [4. GPT ìµœì¢… ì¶”ì²œ] ìµœì¢… ë°˜í™˜ë  ì¥í•™ê¸ˆ ìˆ˜: {len(final_results)}")
    # ë°˜í™˜ êµ¬ì¡°: [{'product_id': '...', 'reason': '...', 'scholarship': <obj>}, ...]
    return final_results


# ------------------------------------------------------------------------------
# --- 4ë‹¨ê³„: ì´ê´„ ì§€íœ˜ í•¨ìˆ˜ ---
# ------------------------------------------------------------------------------

def recommend(user_id: int) -> List[Dict]:
    """ì£¼ì–´ì§„ ì‚¬ìš©ì IDì— ëŒ€í•´ ì¥í•™ê¸ˆì„ ì¶”ì²œí•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print(f"DEBUG: [ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œì‘] ì‚¬ìš©ì ID: {user_id}")
    try:
        # ğŸš¨ UserScholarship ë° Scholarship ëª¨ë¸ì€ ì‹¤ì œ DB í™˜ê²½ì— ë§ê²Œ ì •ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
        user_profile = UserScholarship.objects.get(user_id=user_id)
    except UserScholarship.DoesNotExist:
        print(f"ì˜¤ë¥˜: ì‚¬ìš©ì ID {user_id}ì— í•´ë‹¹í•˜ëŠ” í”„ë¡œí•„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    except NameError:
        # ëª¨ë¸ í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ìœ„í•œ ì„ì‹œ ì²˜ë¦¬ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì œê±°)
        print(f"ì˜¤ë¥˜: UserScholarship í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹¤ì œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return []

    scholarships = Scholarship.objects.all()
    # ğŸš¨ ë‚ ì§œ í•„í„°ë§ í™œì„±í™” ì—¬ë¶€ëŠ” í•„ìš”ì— ë”°ë¼ ê²°ì •
    # scholarships = filter_scholarships_by_date(scholarships)
    
    scholarships = filter_basic(scholarships, user_profile) # 2. ê¸°ë³¸ ìê²© í•„í„°ë§
    scholarships = filter_by_region_preprocessed(scholarships, user_profile) # 3. ì§€ì—­ ìê²© í•„í„°ë§
    
    # ìµœì¢… ë­í‚¹ ë° ì¶”ì²œ ì‚¬ìœ  ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ (List[Dict] ë°˜í™˜)
    final_recommendations = recommend_final_scholarships_by_gpt(scholarships, user_profile) 
    
    print(f"DEBUG: [ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ] ìµœì¢… ì¶”ì²œ ì¥í•™ê¸ˆ ìˆ˜: {len(final_recommendations)}")
    
    # ë·°ë¡œ ë°˜í™˜í•  ë•Œ í•„ìš”í•œ ìµœì†Œ ì •ë³´(product_id, reason)ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
    return [
        {
            "product_id": r['product_id'],  # GPTê°€ ë°˜í™˜í•œ ID
            "reason": r['reason'],          # GPTê°€ ì‘ì„±í•œ ì¶”ì²œ ì‚¬ìœ 
        }
        for r in final_recommendations
    ]