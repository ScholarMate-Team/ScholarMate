import openai
import time
import json
import re
import requests
import urllib3
from datetime import datetime
from django.db.models import QuerySet, Q, Case, When, Value
from django.conf import settings
from scholarships.models import Scholarship
from userinfor.models import UserScholarship
from django.db import models
from typing import List, Dict # íƒ€ì… íŒíŠ¸ ì¶”ê°€

# --- API í‚¤ ì„¤ì • ---
openai.api_key = settings.OPENAI_API_KEY

# (GPT ìƒí˜¸ì‘ìš© í—¬í¼ í•¨ìˆ˜ë“¤ì€ ë³€ê²½ ì—†ìŒ)
def call_gpt(prompt: str, max_retries: int = 3, delay: int = 2) -> str:
    """OpenAI GPT ëª¨ë¸ì„ í˜¸ì¶œí•˜ê³  ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë©°, ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ìë™ ì¬ì‹œë„í•©ë‹ˆë‹¤."""

    for attempt in range(1, max_retries + 1):

        try:
            response = openai.ChatCompletion.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "ë‹¹ì‹ ì€ ì¥í•™ê¸ˆ ì¶”ì²œ ì‚¬ìœ ë¥¼ ì‘ì„±í•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                            "í•­ìƒ êµ¬ì²´ì ì´ê³  ë¬¸ë‹¨í˜•ìœ¼ë¡œ, ìµœì†Œ 2ë¬¸ì¥ ì´ìƒìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.4,
                request_timeout=120,   # ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„±ì„ ìœ„í•´ 60ì´ˆ ìœ ì§€
            )

            gpt_response_content = response["choices"][0]["message"]["content"]

            print("DEBUG: [GPT ì‘ë‹µ ì›ë³¸]")
            print(gpt_response_content)

            return gpt_response_content

        # ---- OpenAI API ì˜¤ë¥˜ (ì„œë²„ ì˜¤ë¥˜, ë ˆì´íŠ¸ ë¦¬ë°‹ ë“±)
        except openai.error.OpenAIError as e:
            print(f"[GPT ERROR] OpenAI API ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt}/{max_retries}): {e}")

        # ---- ë„¤íŠ¸ì›Œí¬ ê³„ì¸µ ì˜¤ë¥˜ (ë„ˆ ë¡œê·¸ì—ì„œ ë°œê²¬ëœ SSL/TLS ì˜¤ë¥˜ í¬í•¨)
        except (requests.exceptions.RequestException,
                urllib3.exceptions.ProtocolError,
                urllib3.exceptions.ReadTimeoutError,
                urllib3.exceptions.NewConnectionError,
                urllib3.exceptions.MaxRetryError) as e:
            print(f"[NETWORK ERROR] ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt}/{max_retries}): {e}")

        # ---- ê·¸ ì™¸ ëª¨ë“  ì˜ˆì™¸ (ì¼ë°˜ì ì¸ ëŸ°íƒ€ì„ ì˜¤ë¥˜)
        except Exception as e:
            print(f"[UNKNOWN ERROR] ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt}/{max_retries}): {e}")

        # ì¬ì‹œë„ í•„ìš”
        if attempt < max_retries:
            print(f"[RETRY] {delay}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤â€¦")
            time.sleep(delay)

    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ â†’ 500 ë°©ì§€ ìœ„í•´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
    print("[FAIL] GPT í˜¸ì¶œ ì‹¤íŒ¨: ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨, ë¹ˆ ë¬¸ìì—´ ë°˜í™˜")
    return ""

def extract_json_from_gpt_response(gpt_response_content: str) -> str:
    """GPT ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON ë°°ì—´ ë˜ëŠ” ê°ì²´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    match = re.search(r"\[.*\]|{.*}", gpt_response_content, re.DOTALL)
    return match.group(0) if match else "[]"

def safe_parse_json(response_text: str):
    """GPT ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSONì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±í•©ë‹ˆë‹¤."""
    try:
        json_str = extract_json_from_gpt_response(response_text)
        return json.loads(json_str) if json_str.strip() else []
    except (json.JSONDecodeError, Exception) as e:
        print(f"ì˜¤ë¥˜: JSON íŒŒì‹± ì‹¤íŒ¨: {e} - ì‘ë‹µ ë‚´ìš©: '{response_text[:200]}...'")
        return []

# (ë°ì´í„° ì¤€ë¹„ í—¬í¼ í•¨ìˆ˜ëŠ” ë³€ê²½ ì—†ìŒ)
def _scholarship_to_simplified_dict(scholarship_obj):
    """GPTê°€ ìƒì„¸ ë¹„êµë¥¼ í•  ìˆ˜ ìˆë„ë¡, ì›ë³¸ ìƒì„¸ í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤."""     
    return {
        "product_id": scholarship_obj.product_id,
        "name": scholarship_obj.name, 
        "product_type": scholarship_obj.product_type,
        "university_type": scholarship_obj.university_type,
        "academic_year_type": scholarship_obj.academic_year_type,
        "major_field": scholarship_obj.major_field, 
        "region": scholarship_obj.region,
        "grade_criteria_details": scholarship_obj.grade_criteria_details,
        "income_criteria_details": scholarship_obj.income_criteria_details,
        "specific_qualification_details": scholarship_obj.specific_qualification_details,
    }

# (DB ì‚¬ì „ í•„í„°ë§ í•¨ìˆ˜ë“¤ì€ ë³€ê²½ ì—†ìŒ)
def filter_scholarships_by_date(scholarships_queryset: QuerySet) -> QuerySet:
    # ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    current_date = datetime.now().date()
    filtered_qs = scholarships_queryset.filter(
            recruitment_start__lte=current_date,
            recruitment_end__gte=current_date
        )
    print(f"DEBUG: [0. ë‚ ì§œ í•„í„°ë§] í•„í„°ë§ í›„ ì¥í•™ê¸ˆ ìˆ˜: {filtered_qs.count()}")
    return filtered_qs

def filter_basic(scholarships_queryset: QuerySet, user_profile: UserScholarship) -> QuerySet:
    # ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    print(f"DEBUG: [1. ê¸°ë³¸ í•„í„°ë§] ì‚¬ìš©ì í”„ë¡œí•„: ëŒ€í•™='{user_profile.university_type}', í•™ë…„='{user_profile.academic_year_type}', ì „ê³µ='{user_profile.major_field}'")
    current_filtered_qs = scholarships_queryset
    
    # ëŒ€í•™ ìœ í˜• í•„í„°ë§
    if user_profile.university_type and user_profile.university_type.strip():
        all_university_types = current_filtered_qs.values_list('university_type', flat=True).distinct()
        user_univ_type_normalized = user_profile.university_type.strip().replace('-', '~')
        matching_types = [db_type for db_type in all_university_types if user_univ_type_normalized in db_type.replace('-', '~')]
        if matching_types:
            current_filtered_qs = current_filtered_qs.filter(university_type__in=matching_types)
    
    # í•™ë…„ ìœ í˜• í•„í„°ë§
    if user_profile.academic_year_type and user_profile.academic_year_type.strip():
        all_academic_years_in_db = current_filtered_qs.values_list('academic_year_type', flat=True).distinct()
        user_academic_year_normalized = user_profile.academic_year_type.strip().replace(' ', '')
        matching_academic_years = [db_year for db_year in all_academic_years_in_db if user_academic_year_normalized in db_year.replace(' ', '')]
        if matching_academic_years:
            current_filtered_qs = current_filtered_qs.filter(academic_year_type__in=matching_academic_years)
            
    # í•™ê³¼(ì „ê³µ) í•„í„°ë§
    user_major_field = getattr(user_profile, 'major_field', None)
    if user_major_field and user_major_field.strip():
        all_majors_in_db = current_filtered_qs.values_list('major_field', flat=True).distinct()
        user_major_normalized = user_major_field.strip()
        all_major_keywords = ["í•´ë‹¹ì—†ìŒ", "ì œí•œì—†ìŒ", "ì „ê³µë¬´ê´€", "íŠ¹ì •í•™ê³¼"] 
        q_objects = Q(major_field__icontains=user_major_normalized) | Q(major_field__in=all_major_keywords)
        current_filtered_qs = current_filtered_qs.filter(q_objects)

    print(f"DEBUG: [1. ê¸°ë³¸ í•„í„°ë§] ìµœì¢… ê¸°ë³¸ í•„í„°ë§ ì ìš© í›„ ì¥í•™ê¸ˆ ìˆ˜: {current_filtered_qs.count()}")
    return current_filtered_qs

def filter_by_region_preprocessed(scholarships_queryset: QuerySet, user_profile: UserScholarship) -> QuerySet:
    user_region_do = getattr(user_profile, 'region', '') or ""
    user_district = getattr(user_profile, 'district', '') or ""
    
    user_region_parts = list(filter(None, [user_region_do.strip(), user_district.strip()]))
    full_user_region = ' '.join(user_region_parts)
    print(f"DEBUG: [2. ì§€ì—­ í•„í„°ë§] ì¡°í•©ëœ ì‚¬ìš©ì ì§€ì—­: '{full_user_region}'")

    if not full_user_region:
        return scholarships_queryset.filter(region__icontains="ì „êµ­")

    exact_match_conditions = [full_user_region] + user_region_parts
    q_objects = Q(region__in=exact_match_conditions) | Q(region__icontains="ì „êµ­")
    
    filtered_qs = scholarships_queryset.filter(q_objects).distinct()
    print(f"DEBUG: [2. ì§€ì—­ í•„í„°ë§] í•„í„°ë§ í›„ ì¥í•™ê¸ˆ ìˆ˜: {filtered_qs.count()}")
    return filtered_qs


# --- 2ë‹¨ê³„: GPT ìµœì¢… ë­í‚¹ í•¨ìˆ˜ --- 

# ğŸš¨ í•¨ìˆ˜ ë°˜í™˜ íƒ€ì…ì„ List[Dict]ë¡œ ëª…í™•íˆ ë³€ê²½í•©ë‹ˆë‹¤.
def recommend_final_scholarships_by_gpt(filtered_scholarships_queryset: QuerySet, user_profile: UserScholarship) -> List[Dict]:
    """
    GPTì—ê²Œ ìµœì¢… ì¶”ì²œ ì´ìœ ê¹Œì§€ ì‘ì„±í•˜ë„ë¡ ìœ„ì„í•˜ê³ , ê²°ê³¼ë¥¼ Scholarship ê°ì²´ì™€ Reasonì„ í¬í•¨í•œ
    ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì—¬ í›„ì† ì²˜ë¦¬ê°€ ìš©ì´í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    """
    print(f"DEBUG: [3. GPT ìµœì¢… ì¶”ì²œ] GPT í˜¸ì¶œ ì „ í›„ë³´êµ° ìˆ˜: {filtered_scholarships_queryset.count()}")
    if filtered_scholarships_queryset.count() == 0:
        return []

    # --- 1. ì ìˆ˜ì œ ìƒ˜í”Œë§ ---
    user_region_do = getattr(user_profile, 'region', '') or ""
    user_district = getattr(user_profile, 'district', '') or ""
    full_user_region = ' '.join(filter(None, [user_region_do.strip(), user_district.strip()]))
    user_major = getattr(user_profile, 'major_field', '') or ""

    score_annotation = Case(
        When(region=full_user_region, then=Value(10)),
        When(region=user_region_do, then=Value(7)),
        When(major_field__icontains=user_major, then=Value(5)),
        When(region__icontains="ì „êµ­", then=Value(1)),
        default=Value(0),
        output_field=models.IntegerField()
    )
    
    scored_queryset = filtered_scholarships_queryset.annotate(
        relevance_score=score_annotation
    ).order_by('-relevance_score')

    sample_size = 15
    actual_sample_size = min(scored_queryset.count(), sample_size)
    sampled_queryset_for_gpt = scored_queryset[:actual_sample_size]
    
    print(f"DEBUG: [3. GPT ìµœì¢… ì¶”ì²œ] ì ìˆ˜ì œ ìƒ˜í”Œë§ í›„ GPT ë¶„ì„ ëŒ€ìƒ ìˆ˜: {len(sampled_queryset_for_gpt)}")
    sampled_scholarships_for_gpt = [_scholarship_to_simplified_dict(s) for s in sampled_queryset_for_gpt]
    
    # --- 2. ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ (í”„ë¡¬í”„íŠ¸ëŠ” ìˆ˜ì • ì—†ìŒ) ---
    user_info_dict = user_profile.to_dict()
    user_info_dict['region'] = full_user_region
    user_info_dict.pop('district', None)
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í”„ë¡œí•„ê³¼ ì¥í•™ê¸ˆ ìê²© ì¡°ê±´ì„ ë¹„êµí•˜ì—¬, ê°œì¸í™”ëœ ì¶”ì²œ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ëŠ” AI ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
    
    [ì‚¬ìš©ì í”„ë¡œí•„]
    {json.dumps(user_info_dict, ensure_ascii=False, indent=2)}

    [ë¶„ì„ ëŒ€ìƒ ì¥í•™ê¸ˆ ëª©ë¡]
    {json.dumps(sampled_scholarships_for_gpt, ensure_ascii=False, indent=2)}
    
    [ì—…ë¬´ ì§€ì‹œ]

    ì‚¬ìš©ì í”„ë¡œí•„ê³¼ ì¥í•™ê¸ˆ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬, ëª©ë¡ ë‚´ì— ìˆëŠ” **ì´ {actual_sample_size}ê°œì˜ ì¥í•™ê¸ˆ**ì„ ì í•©ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

    **[ë§¤ìš° ì¤‘ìš”í•œ ê·œì¹™]**

    1.  **ì‚¬ì‹¤ ê¸°ë°˜ ì‘ì„±:** reason'ì„ ì‘ì„±í•  ë•ŒëŠ” ì•„ë˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¥´ê³ , **ê·œì¹™ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ** ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”. ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
        ê·œì¹™1.  **ì§€ì—­ ì¡°ê±´:** ì‚¬ìš©ìì˜ ì§€ì—­('{user_info_dict.get("region")}')ê³¼ ì¥í•™ê¸ˆì˜ 'region'ì´ êµ¬ì²´ì ìœ¼ë¡œ ì¼ì¹˜í• ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ì„¸ìš”. 'ì „êµ­'ì€ ê·¸ ë‹¤ìŒì…ë‹ˆë‹¤.
        ê·œì¹™2.  **ì„±ì  ì¡°ê±´:** ì‚¬ìš©ìì˜ ì„±ì (gpa_last_semester, gpa_overall)ê³¼ ì¥í•™ê¸ˆì˜ 'grade_criteria_details'ë¥¼ ë¹„êµí•˜ì—¬, ê¸°ì¤€ì„ ì¶©ì¡±í•˜ë©´ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.
        ê·œì¹™3.  **ì†Œë“ ì¡°ê±´:** ì‚¬ìš©ìì˜ ì†Œë“ë¶„ìœ„('income_level')ì™€ ì¥í•™ê¸ˆì˜ 'income_criteria_details'ë¥¼ ë¹„êµí•˜ì—¬, ê¸°ì¤€ì— ë¶€í•©í•˜ë©´ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”.
        ê·œì¹™4.  **íŠ¹ì • ìê²© ì¡°ê±´ (ê°€ì‚°ì  í•­ëª©):**
            - ë§Œì•½ ì‚¬ìš©ìì˜ 'is_multi_cultural_family'ê°€ Trueì´ê³ , ì¥í•™ê¸ˆ ì„¤ëª…(ì£¼ë¡œ 'specific_qualification_details')ì— 'ë‹¤ë¬¸í™”'ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë†’ì€ ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.
            - ë§Œì•½ ì‚¬ìš©ìì˜ 'is_single_parent_family'ê°€ Trueì´ê³ , ì¥í•™ê¸ˆì˜ 'income_criteria_details'ì— 'í•œë¶€ëª¨', 'ê°€ì •í˜•í¸', 'ê²½ì œì‚¬ì •'ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë†’ì€ ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.
            - ë§Œì•½ ì‚¬ìš©ìì˜ 'is_multiple_children_family'ê°€ Trueì´ê³ , ì¥í•™ê¸ˆì˜'income_criteria_details'ì— 'ë‹¤ìë…€'ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë†’ì€ ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.
            - ë§Œì•½ ì‚¬ìš©ìì˜ 'is_national_merit'ê°€ Trueì´ê³ , ì¥í•™ê¸ˆì˜'income_criteria_details'ì— 'êµ­ê°€ìœ ê³µì' ë˜ëŠ” 'ë³´í›ˆ'ì´ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë†’ì€ ê°€ì‚°ì ì„ ì£¼ì„¸ìš”.
        ê·œì¹™5.  **ê¸°íƒ€ ì¡°ê±´:** ìœ„ ì¡°ê±´ ì™¸ì—ë„ ì‚¬ìš©ìì˜ ì „ê³µ, í•™ë…„ ë“±ì´ ì¥í•™ê¸ˆì˜ ì¡°ê±´ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì„¸ìš”.

    2. **ì¶”ì²œ ì—¬ë¶€ ê¸°ì¤€:** ì¥í•™ê¸ˆì˜ ëª¨ë“  í•„ìˆ˜ ì¡°ê±´(ì§€ì—­, ì„±ì , ì†Œë“, ì „ê³µ, í•™ë…„ ë“±)ì„ ì‚¬ìš©ìê°€ ì¶©ì¡±í•˜ëŠ” ê²½ìš°ì—ë§Œ ì¶”ì²œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ë¼ë„ ëª…í™•íˆ ì¶©ì¡±í•˜ì§€ ì•Šë‹¤ë©´ ì¶”ì²œ ì¥í•™ê¸ˆìœ¼ë¡œ ì„ ì •í•˜ì§€ ë§ˆì„¸ìš”. 

    3.  **êµ¬ì²´ì ì¸ ì´ìœ  ì œì‹œ:** 'reason'ì—ëŠ” ì™œ ì´ ì¥í•™ê¸ˆì´ ì‚¬ìš©ìì—ê²Œ ì í•©í•œì§€, ì–´ë–¤ ì¡°ê±´(ì§€ì—­, ì„±ì , ì†Œë“, ì „ê³µ, í•™ë…„, íŠ¹ì • ìê²© ë“±)ì´ ì–´ë–»ê²Œ ë¶€í•©í•˜ëŠ”ì§€ë¥¼ **2ë¬¸ì¥ ì´ìƒ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ í˜•íƒœë¡œ** ì‘ì„±í•˜ì„¸ìš”.
    + ì˜ˆë¥¼ ë“¤ì–´, â€œ{user_info_dict.get("name")}ëŠ” ê²½ê¸° ì§€ì—­ì˜ 4í•™ë…„ìƒìœ¼ë¡œ, í•´ë‹¹ ì¥í•™ê¸ˆì˜ ì§€ì—­ ìš”ê±´ê³¼ í•™ë…„ ì¡°ê±´ì„ ëª¨ë‘ ì¶©ì¡±í•©ë‹ˆë‹¤. ë˜í•œ ì„±ì  ê¸°ì¤€(3.5 ì´ìƒ)ì„ ë§Œì¡±í•˜ë©°, ì „êµ­ ë‹¨ìœ„ë¡œ ì§€ì› ê°€ëŠ¥í•´ ì ‘ê·¼ì„±ì´ ë†’ìŠµë‹ˆë‹¤.â€ ì™€ ê°™ì€ í˜•íƒœë¡œ ì‘ì„±í•˜ì„¸ìš”.
    
    **[ì¶œë ¥ í˜•ì‹]**
    - ê° í•­ëª©ì€ 'product_id'ì™€ 'reason' ë‘ ê°œì˜ í‚¤ë¥¼ ê°€ì§„ JSON ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.
    - 'reason'ì€ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìµœì¢… ì¶”ì²œ ì‚¬ìœ (í•œêµ­ì–´ ë¬¸ìì—´)ì…ë‹ˆë‹¤. ë§Œì•½ ê·œì¹™4ë¡œ ì¸í•´ ê°€ì‚°ì ì„ ì–»ì€ ê²½ìš°, 'reason'ì— ê·¸ì™€ ê´€ë ¨ëœ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì„œìˆ í•˜ì„¸ìš”.
    - 'product_id'ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”.

    """

   # --- 3. GPT í˜¸ì¶œ ë° ê²°ê³¼ ì²˜ë¦¬ ---
    gpt_response_content = call_gpt(prompt)
    parsed_response = safe_parse_json(gpt_response_content)

    if not isinstance(parsed_response, list) or not parsed_response:
        # í´ë°± ì‹œì—ëŠ” ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ë°˜í™˜ (Scholarship ê°ì²´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
        # ğŸš¨ í´ë°± ì‹œì—ë„ ë·°ì—ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½
        fallback_qs = scored_queryset[:min(scored_queryset.count(), 15)]
        return [
            {"product_id": s.product_id, "reason": "GPT ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì¶”ì²œ", "scholarship": s}
            for s in fallback_qs
        ]


    # GPTê°€ ë°˜í™˜í•œ IDê°€ ìœ íš¨í•œì§€(ìƒ˜í”Œë§ í›„ë³´êµ°ì— ìˆëŠ”ì§€) ìµœì†Œí•œì˜ ê²€ì¦ë§Œ ìˆ˜í–‰
    valid_recommendations = []
    sampled_ids_map = {s.product_id: s for s in sampled_queryset_for_gpt}
    
    print("\n" + "="*25 + " GPT ì‘ë‹µ ìµœì†Œ ê²€ì¦ ì‹œì‘ " + "="*25)
    for item in parsed_response:
        product_id = item.get('product_id')
        if isinstance(item, dict) and product_id and product_id in sampled_ids_map:
            # ğŸš¨ ìœ íš¨í•œ í•­ëª©ì— Scholarship ê°ì²´ë¥¼ ì¶”ê°€í•˜ì—¬ ì €ì¥
            item['scholarship'] = sampled_ids_map[product_id]
            valid_recommendations.append(item)
            print(f" Â - âœ… ê²€ì¦ ì„±ê³µ (ID ìœ íš¨): {product_id}, ì´ìœ : {item.get('reason')}")
        else:
            print(f" Â - âŒ ê²€ì¦ ì‹¤íŒ¨ (ID ì˜¤ë¥˜ ë˜ëŠ” í™˜ê°): {product_id}")
    print("="*25 + " GPT ì‘ë‹µ ìµœì†Œ ê²€ì¦ ì™„ë£Œ " + "="*25 + "\n")

    if not valid_recommendations:
        print("ê²½ê³ : ê²€ì¦ì„ í†µê³¼í•œ ì¶”ì²œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì ìˆ˜ ê¸°ë°˜ í´ë°± ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        # í´ë°± ë¡œì§ì—ì„œë„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        fallback_qs = scored_queryset[:min(scored_queryset.count(), 15)]
        return [
            {"product_id": s.product_id, "reason": "GPT ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì¶”ì²œ", "scholarship": s}
            for s in fallback_qs
        ]

    # --- 4. ìµœì¢… ê²°ê³¼ ìƒì„± ---
    # valid_recommendationsëŠ” ì´ë¯¸ GPTì˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    final_results = valid_recommendations[:15] # ìƒìœ„ 15ê°œ (í˜¹ì€ ì‹¤ì œ ê²€ì¦ëœ ê°œìˆ˜)

    # ğŸš¨ í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì—ì„œ ìµœì¢… ì¿¼ë¦¬ì…‹ì„ í•„í„°ë§í•˜ëŠ” ëŒ€ì‹ ,
    # valid_recommendationsì—ì„œ í•„ìš”í•œ ì •ë³´(ID, reason)ì™€ Scholarship ê°ì²´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
    # (ì´ë¯¸ valid_recommendationsì— ê°ì²´ê°€ ë‹´ê²¨ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ DB ì¿¼ë¦¬ ë¶ˆí•„ìš”)
    
    print(f"DEBUG: [4. GPT ìµœì¢… ì¶”ì²œ] ìµœì¢… ë°˜í™˜ë  ì¥í•™ê¸ˆ ìˆ˜: {len(final_results)}")
    # ğŸš¨ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜: [{'product_id': '...', 'reason': '...', 'scholarship': <obj>}, ...]
    return final_results


# --- ì´ê´„ ì§€íœ˜ í•¨ìˆ˜ ---
# ğŸš¨ í•¨ìˆ˜ ë°˜í™˜ íƒ€ì…ì„ List[Dict]ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
def recommend(user_id: int) -> List[Dict]:
    """ì£¼ì–´ì§„ ì‚¬ìš©ì IDì— ëŒ€í•´ ì¥í•™ê¸ˆì„ ì¶”ì²œí•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print(f"DEBUG: [ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œì‘] ì‚¬ìš©ì ID: {user_id}")
    try:
        user_profile = UserScholarship.objects.get(user_id=user_id)
    except UserScholarship.DoesNotExist:
        print(f"ì˜¤ë¥˜: ì‚¬ìš©ì ID {user_id}ì— í•´ë‹¹í•˜ëŠ” í”„ë¡œí•„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    scholarships = Scholarship.objects.all()
    scholarships = filter_scholarships_by_date(scholarships) # 1. ë‚ ì§œ í•„í„°ë§ (í•„ìš”ì‹œ í™œì„±í™”)
    scholarships = filter_basic(scholarships, user_profile) # 2. ê¸°ë³¸ ìê²© í•„í„°ë§
    scholarships = filter_by_region_preprocessed(scholarships, user_profile) # 3. ì§€ì—­ ìê²© í•„í„°ë§
    
    # ğŸš¨ recommend_final_scholarships_by_gptëŠ” ì´ì œ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    final_recommendations = recommend_final_scholarships_by_gpt(scholarships, user_profile) # 4. ìµœì¢… ë­í‚¹
    
    print(f"DEBUG: [ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ] ìµœì¢… ì¶”ì²œ ì¥í•™ê¸ˆ ìˆ˜: {len(final_recommendations)}")
    
    # ğŸš¨ ë°˜í™˜ êµ¬ì¡° ìˆ˜ì •: 'r'ì´ ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ ë”•ì…”ë„ˆë¦¬ í‚¤ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.
    # ë·°ì—ì„œ í•„ìš”í•œ ìµœì†Œí•œì˜ ì •ë³´(product_id, reason)ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    return [
        {
            "product_id": r['product_id'],  # ë”•ì…”ë„ˆë¦¬ í‚¤ë¡œ ì ‘ê·¼
            "reason": r['reason'],          # ë”•ì…”ë„ˆë¦¬ í‚¤ë¡œ ì ‘ê·¼
        }
        for r in final_recommendations
    ]